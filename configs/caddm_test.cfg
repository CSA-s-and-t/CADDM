# Face Crop Param
crop_face:
  face_width: 80
  output_size: 224
  scale: 0.9

# Artifact Detection Module.
adm_det:
  min_dim: 224
  aspect_ratios: [[1], [1], [1], [1]]
  feature_maps: [7, 5, 3, 1]
  steps: [32, 45, 75, 224]
  min_sizes: [40, 80, 120, 224]
  max_sizes: [80, 120, 160, 224]
  clip: True
  variance: [0.1]
  name: deepfake

# The Size of the Sliding Window.
sliding_win:
  prior_bbox: [[40, 80], [80, 120], [120, 160], [224, 224]]

# number of frames to extract from each video
num_frames: 10

# config info for processing testing data
dataset:
  # path to folder containing all videos for testing
  video_path: "D:/collated"
  # path to folder where frames from videos will be saved
  img_path: "D:/collated/test_images"
  # specify the video number to start from in case processing is interrupted. set to 0 if entire dataset is to be processed
  start_from: 0
  ld_path: "D:/collated/test_images/ldm.json"
  name: 'Test'

# model info
model:
  backbone: "efficientnet-b4"
  ckpt: "./checkpoints/efficientnet-b4.pkl"

# test params
test:
  batch_size: 16
